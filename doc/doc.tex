
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2019}
%This is a template for producing LIPIcs articles. 
%See lipics-manual.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle

\title{Documentation of floatsmt}

\author{Felix Griesau}{Karlsruhe Institute of Technology, Germany}{TODO}{}{}
\author{Marc Huisinga}{Karlsruhe Institute of Technology, Germany}{mhuisi@protonmail.com}{}{}

\authorrunning{F. Griesau and M. Huisinga}

\Copyright{Felix Griesau and Marc Huisinga}

\ccsdesc[500]{Theory of computation~Automated reasoning}

\keywords{Automated theorem proving, SMT solving, Z3, Floating point, IEEE 754, smtlib}

\category{}

\relatedversion{}

\supplement{\url{https://github.com/mhuisi/float-smt}}

\acknowledgements{}

\nolinenumbers

\hideLIPIcs 

\lstset{language=Python}

\begin{document}

\maketitle

\begin{abstract}
This report documents the floatsmt library, which implements a floating point theory using the Z3 SMT solver. 
\end{abstract}

% Use \autoref for references and lstlisting for code.

\section{Introduction}
The IEEE 754 floating point standard \cite{ieee} is complex. Manually ensuring the correctness of programs that use floating point operations requires great care: 
\begin{itemize}
\item Edge cases like $+0$, $-0$, $+\infty$, $-\infty$ and \verb|NaN| need to be handled correctly, since all operations behave differently when applied to one of these edge cases.
\item Rounding errors need to be kept in check. Depending on the operation, the values and even the rounding mode involved, rounding errors may grow very large.
\item Operations on normals and subnormals can unintentionally produce one of the above edge cases in the situation of an underflow or an overflow.
\end{itemize}
Aside from these issues, floating point operations can always be understood in terms of their semantics, where a float is mapped to its real number value, the corresponding operation is performed over the reals and the result is rounded and mapped back to the floating point numbers.

Unfortunately, implementations of the floating point standard cannot easily and efficiently perform operations on the real numbers. Hence, implementations need to perform operations on floats using bit vectors and ensure that the result is still rounded correctly. This is even more error-prone than the semantical view of floats that users of these implementations work with, and very costly if erroneous\footnote{See \url{https://web.archive.org/web/20190618044444/http://www.trnicely.net/pentbug/pentbug.html} for an infamous example}. 

To combat these complexities, verification tools like SMT solvers have recently begun supporting floating point theories \cite{semantics}. These theories can be used to prove properties about implementations of the floating point standard and programs that use floats, ensuring correctness in regard to these properties.

But who watches the watchmen? How do we guarantee that the SMT solver implementation of the floating point theory is itself correct? After all, such an SMT solver implementation needs to surpass the same complexities as other floating point implementations.

To help reduce this uncertainty in the sense of ``trust, but verify'', we implemented floatsmt, a floating point theory for the Z3 SMT solver \cite{z3}. floatsmt was implemented from scratch, not based on any reference implementation and then verified against Z3's own floating point theory. In our verification, we found no bugs in Z3's theory, gaining a significant amount of trust in the floating point theory of Z3 in the process. This report details our decisions for the design and implementation of floatsmt.

\section{Usage instructions}
floatsmt is a Python library for the Z3 Python interface ``z3py''.

\subsection{Installation}
\begin{enumerate}
\item Install Python ($\geq$ 3.7.4) (\url{https://www.python.org/downloads/}).
\item Install the z3-solver package ($\geq$ 4.8.8.0) via \verb|pip install z3-solver| (\url{https://pypi.org/project/z3-solver/}).
\item Install git (\url{https://git-scm.com/}).
\item Clone the repository via \verb|git clone https://github.com/mhuisi/float-smt|.
\item Copy the \verb|floatsmt| directory to where the library will be used.
\item Add \verb|import floatsmt| to the top of the Python file where the library will be used and get started.
\end{enumerate} 

\subsection{Usage}
What follows is a code snippet to show how the library is used.
\begin{lstlisting}
from floatsmt.api import *

# Sets the rounding mode globally.
# Must be one of 
# {NearestTiesToEven,NearestTiesAwayFromZero,Up,Down,Truncate}.
set_default_rm(NearestTiesToEven)

# Create the floating point sort which we will use.
# floatsmt supports arbitrary bit widths.
# The first argument denotes the mantissa width,
# the second argument denotes the exponent width.
# (23, 8) is a standard 32 bit float.
sort = FloatSort(23, 8)

# Create a float constant from a specific bit representation.
x = SMTFloat.FloatVal(0, 0b1011, 0b1111, sort)
# Create a float constant from a decimal representation. 
# The mode for rounding from decimal to binary must be one of
# {NEAREST_TIE_TO_EVEN,NEAREST_TIE_AWAY_FROM_ZERO,UP,DOWN,TRUNCATE}.
y = SMTFloat.FloatValDec("0.123e-2", 
      converter.RoundingMode.NEAREST_TIE_TO_EVEN, sort)

# Many operations can be used via Python operator overloading.
print(x)
print(x + y)
print(x * x)
print(x - y) 
print(x / y)

# Constants can be created via 
# FloatConst(name, mantissa_width, exponent_width)
# and then used for proofs.
x = SMTFloat.FloatConst("x", 23, 8)
y = SMTFloat.FloatConst("y", 23, 8)

# E.g. in floats always x > 0 & y > 0 => x * y >= 0
zero = SMTFloat.FloatValZero(FloatSort(23, 8))
solver = Solver()
condition = Implies(And(x > zero, y > zero), x * y >= zero)
solver.add(Not(condition))
print(solver.check())
\end{lstlisting}

\subsection{Testing}
The tests reside in \verb|tests/test.py|. Due to the costly validation against Z3 in many of these tests, they are best ran individually from the root directory. \\
\verb|python -m unittest tests.test.Operations.test_mul| runs a number of individual regression tests and then validates the floatsmt multiplication for half-floats against Z3.

\section{Project structure}
% TODO: superficially explain the different components of the library (sorts, operations, packing etc.) and the file/module organization. shortly explain api.py and its relation to the other stuff so we don't need to explain api.py later.
We will begin by outlining the conceptual structure of the library and then detail the concrete file structure. 

Each floating point value has an associated sort, which can roughly be understood as the type of the value. The sort contains the mantissa bit width and the exponent bit width for the floating point value. As such, floatsmt is entirely polymorphic over these widths. 
Given a sort, there are multiple different constructors for floating point values. These enable the creation of either floats with specific Python-/Z3 values, or float constants, which can be seen as existentially-quantified free variables. All of these constructors produce Z3 values.
Once a float value has been created, multiple operations and predicates can be used on it. The arithmetical operations are the most complex part of the library and work in multiple steps. First, both floats are pre-processed into a format that is easier to handle when calculating the result of the operations. Second, the corresponding operation is executed on the pre-processed float. Operations are fairly unrestricted in terms of how they can manipulate these preprocessed floats. Finally, the result of the operation is post-processed, where the result of the operation in the pre-processed format is converted back into a proper float.

Let us now explain the purpose of each file in the directory structure.
\begin{itemize}
	\item \verb|api.py|: Wraps user-facing functions and provides operator-overloading for some.
	\item \verb|constructors.py|: Provides functions that create floating point values of a specific sort, like a constructor that creates a float value from a string in decimal scientific notation.
	\item \verb|conversions.py|: Contains functions that convert floating point values to other Z3 sorts, like bit vectors or Z3 floats.
	\item \verb|converter.py|: Provides a function that parses a string in decimal notation and then converts the resulting decimal float to a binary float, rounding accordingly.
	\item \verb|operations.py|: Implements several arithmetical operations, like $+$, $*$, $|\cdot|$ or $\min$.
	\item \verb|packing.py|: Yields the pre- and post-processing utilities for arithmetical operations, as well as a function that translates between different float sorts.
	\item \verb|predicates.py|: Contains predicates that take floats and produce booleans, like $>=$ or $==$.
	\item \verb|sorts.py|: Implements the floating point sort and a sort for the rounding mode.
	\item \verb|utils.py|: Provides several utility functions, like a function to count leading zeros and several helper functions to ensure that bit vector operations always take arguments of the same width and never overflow when using arbitrary bit width floats.
\end{itemize}


\section{Implementation details}
% TODO: briefly note which functions were implemented and go into detail for interesting functions. explain how interesting functions were implemented, but also why certain design decisions were made.
This section will explain some design decisions and the implementation of all non-trivial functions in floatsmt.

\subsection{Sorts and constructors}
% sorts.py, constructors.py, converter.py
We use a Z3 \verb|DatatypeSort| as sort for our floats. Z3 datatypes provide similar capabilities as algebraic datatypes in other programming languages, and hence allow for multiple constructors, where each constructor stores a number of arguments. Our sort has the following signature:
\begin{lstlisting}
def FloatSort(mantissa_size : int, exponent_size : int) 
    -> DatatypeSortRef
\end{lstlisting}
We use a datatype with a single constructor \verb|mk| that takes three parameters: \verb|sign|, which is a bit vector with a singleton bit width, \verb|mantissa|, which designates a bit vector of the provided mantissa size and finally \verb|exponent|, which also represents a bit vector of a specified size. Z3 tuples are practically the same thing as datatypes with a single constructor, but the fields of a tuple are not named, and hence we chose datatypes for improved readability instead.
Since we also need to handle the different rounding modes within our Z3 theory, we define a Z3 \verb|EnumSort| that encapsulates the different cases.
For simplicity, we restrict the domains of all operations to floats with equal domains, and define a utility function \verb|ensure_eq_sort(a : DatatypeRef, b : DatatypeRef)| to enforce that invariant and throw an exception otherwise.

Most of the constructors are relatively straight-forward, essentially only invoking \verb|mk| before doing some small setup work. The three most fundamental constructors are the following:
\begin{lstlisting}
def FloatConst(name : str, mantissa_size : int, exponent_size : int) 
    -> DatatypeRef
def FloatVar(sign : BitVecRef, mantissa : BitVecRef, 
    exponent : BitVecRef, sort : DatatypeSortRef) -> DatatypeRef
def FloatVal(sign : int, mantissa : int, exponent : int, 
    sort : DatatypeSortRef) -> DatatypeRef
\end{lstlisting}
\verb|FloatVal| takes Python integers, while \verb|FloatVar| takes bit vectors as parameters.
All the other constructors are built on top of these three constructors. For instance, there is a constructor \verb|FloatVarBV| that takes a bit vector representation of a float and produces a floatsmt float, or a constructor \verb|FloatValPosInf| that creates a float representing $+\infty$.
One of the constructors is more involved: \verb|FloatValDec| takes a string representation of a float in decimal scientific notation and a rounding mode for rounding the decimal float to a binary float. In order to process the string parameter into a float, two steps are necessary: First, the float is parsed into a decimal float value of the form $m \cdot 10^e$. Second, the decimal float value is converted into a binary float of the form $m' \cdot 2^{e'}$. Since this conversion is not exact, it needs to be rounded in the process. The parsing is implemented with a regular manual lexer. The conversion is more complicated, since great care must be taken to accurately round the binary float without error. The conversion executes the following steps using Python's big integers:
\begin{enumerate}
	\item The float is normalized: $e$ is incremented and $m$ divided by $10$ until $10 \nmid m$. This way, trailing zeros in $m$ are moved to $e$.
	\item A tuple $(a, b)$ is created that represents the fraction $(a := m) / (10^{-e} =: b)$ if $e < 0$ and $(a := m \cdot 10^e) / (1 =: b)$ otherwise. It will later be used to determine the mantissa of the binary float and the remainder of the division for rounding.
	\item $\lfloor a / b \rfloor$ is scaled into the range $[2^M, 2^{M+1}) \subseteq \mathbb{N}$, where $M$ is the mantissa bit width of the resulting binary float and $[2^M, 2^{M+1})$ is the range that the mantissa needs to be in so that it is normalized. The fraction is scaled by either successively multiplying $a$ by $2$ if $\lfloor a / b \rfloor < 2^M$ or by multiplying $b$ by $2$ if $\lfloor a / b \rfloor \geq 2^{M+1}$. If $a'$ and $b'$ are the new numerator and denominator values, the amount of multiplication steps is tracked in a variable $c$ such that $a' / b' = 2^{-c} \cdot a / b$. This allows us to later adjust the exponent $e' := 2^{E-1}-1 + M + c$ accordingly, where $E$ denotes the exponent bit width, $2^{E-1}-1$ is the bias of the exponent and $M$ is added so that all mantissa bits are moved behind the decimal point. If we reach $e' \leq 0$ during scaling up, i.e. the float is subnormal, we re-adjust by scaling down only one step so that the exponent denotes a normal float. Subnormality will be handled later via the mantissa instead.
	\item $s := \lfloor a / b \rfloor$ and $r := a \text{ mod } b$ are evaluated, where $s$ denotes the significant and $r$ denotes the remainder. Using $r$, we increment $s$ according to the provided rounding mode. Rounding may yield $s = 2^{M+1}$, so if that occurs we set $s := 2^M$ and $c := c + 1$ and thus re-normalize the rounded $s$ into $[2^M, 2^{M+1})$.
	\item The mantissa $m'$ is set to be the binary representation of $s$. If $m'$ has less than $M$ bits, it must be subnormal, and hence we set $e' := 0$. Otherwise, we set $e'$ to be the binary representation of $2^{E-1}-1 + M + c$. If $e' = 2^E - 1$ or it has more than $E$ bits, the resulting float is too large to be represented by a float with $(M, E)$ bits and both $m'$ and $e'$ are set to the representation of $\infty$ to designate the overflow.
	\item Finally, we simply take the sign bit of the original decimal float.
\end{enumerate}

\subsection{Utilities and predicates}
% TODO: utils.py, conversions.py, predicates.py

\subsection{Pre- and postprocessing}
% TODO: packing.py

\subsection{Operations}
% TODO: operations.py

\section{Testing methodology}
% TODO: explain what was tested in test.py and how

\section{Experimental evaluation}
% TODO: evaluate our solver against z3 (and others?) and explain why it performs terribly and how one might improve it

\section{Conclusion}
% TODO: summarize the project and evaluate the outcome, putting emphasis on the correctness verified against z3

\bibliography{doc}

\appendix

\end{document}
